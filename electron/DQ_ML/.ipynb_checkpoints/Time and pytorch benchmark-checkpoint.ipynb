{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98674aa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 10.1293 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import dwong\n",
    "\n",
    "def your_function():\n",
    "    dwong.os.chdir(\"/Users/wongdowling/Desktop/DQ_Dowling/ntuple_1000\")\n",
    "    file=\"electron_520_1000eve.root\"\n",
    "    (coord, wew_center)=dwong.clus_coord(file)\n",
    "    dq_events = dwong.getData(file,\"Events\")\n",
    "    st3_cal_x=dq_events[\"st23\"].Cal_x.tolist()\n",
    "    st3_cal_y=dq_events[\"st23\"].Cal_y.tolist()\n",
    "\n",
    "# Measure the execution time of your_function\n",
    "start_time = time.time()\n",
    "your_function()\n",
    "end_time = time.time()\n",
    "\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Elapsed time: {elapsed_time:.4f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b49c7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "def batched_dot_mul_sum(a, b):\n",
    "    '''Computes batched dot by multiplying and summing'''\n",
    "    return a.mul(b).sum(-1)\n",
    "\n",
    "\n",
    "def batched_dot_bmm(a, b):\n",
    "    '''Computes batched dot by reducing to ``bmm``'''\n",
    "    a = a.reshape(-1, 1, a.shape[-1])\n",
    "    b = b.reshape(-1, b.shape[-1], 1)\n",
    "    return torch.bmm(a, b).flatten(-3)\n",
    "\n",
    "\n",
    "# Input for benchmarking\n",
    "x = torch.randn(10000, 64)\n",
    "\n",
    "# Ensure that both functions compute the same output\n",
    "assert batched_dot_mul_sum(x, x).allclose(batched_dot_bmm(x, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c9a93d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mul_sum(x, x):  455.5 us\n",
      "bmm(x, x):      173.3 us\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "\n",
    "t0 = timeit.Timer(\n",
    "    stmt='batched_dot_mul_sum(x, x)',\n",
    "    setup='from __main__ import batched_dot_mul_sum',\n",
    "    globals={'x': x})\n",
    "\n",
    "t1 = timeit.Timer(\n",
    "    stmt='batched_dot_bmm(x, x)',\n",
    "    setup='from __main__ import batched_dot_bmm',\n",
    "    globals={'x': x})\n",
    "\n",
    "print(f'mul_sum(x, x):  {t0.timeit(100) / 100 * 1e6:>5.1f} us')\n",
    "print(f'bmm(x, x):      {t1.timeit(100) / 100 * 1e6:>5.1f} us')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce5a96b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.benchmark.utils.common.Measurement object at 0x104f8c8e0>\n",
      "batched_dot_mul_sum(x, x)\n",
      "setup: from __main__ import batched_dot_mul_sum\n",
      "  228.98 us\n",
      "  1 measurement, 100 runs , 1 thread\n",
      "<torch.utils.benchmark.utils.common.Measurement object at 0x16e379700>\n",
      "batched_dot_bmm(x, x)\n",
      "setup: from __main__ import batched_dot_bmm\n",
      "  117.85 us\n",
      "  1 measurement, 100 runs , 1 thread\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W ParallelNative.cpp:230] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:230] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n"
     ]
    }
   ],
   "source": [
    "import torch.utils.benchmark as benchmark\n",
    "\n",
    "t0 = benchmark.Timer(\n",
    "    stmt='batched_dot_mul_sum(x, x)',\n",
    "    setup='from __main__ import batched_dot_mul_sum',\n",
    "    globals={'x': x})\n",
    "\n",
    "t1 = benchmark.Timer(\n",
    "    stmt='batched_dot_bmm(x, x)',\n",
    "    setup='from __main__ import batched_dot_bmm',\n",
    "    globals={'x': x})\n",
    "\n",
    "print(t0.timeit(100))\n",
    "print(t1.timeit(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99c0fd1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benchmarking on 10 threads\n",
      "<torch.utils.benchmark.utils.common.Measurement object at 0x104d5ac70>\n",
      "Multithreaded batch dot: Implemented using mul and sum\n",
      "setup: from __main__ import batched_dot_mul_sum\n",
      "  351.79 us\n",
      "  1 measurement, 100 runs , 10 threads\n",
      "<torch.utils.benchmark.utils.common.Measurement object at 0x1051e3730>\n",
      "Multithreaded batch dot: Implemented using bmm\n",
      "setup: from __main__ import batched_dot_bmm\n",
      "  134.00 us\n",
      "  1 measurement, 100 runs , 10 threads\n"
     ]
    }
   ],
   "source": [
    "num_threads = torch.get_num_threads()\n",
    "print(f'Benchmarking on {num_threads} threads')\n",
    "\n",
    "t0 = benchmark.Timer(\n",
    "    stmt='batched_dot_mul_sum(x, x)',\n",
    "    setup='from __main__ import batched_dot_mul_sum',\n",
    "    globals={'x': x},\n",
    "    num_threads=num_threads,\n",
    "    label='Multithreaded batch dot',\n",
    "    sub_label='Implemented using mul and sum')\n",
    "\n",
    "t1 = benchmark.Timer(\n",
    "    stmt='batched_dot_bmm(x, x)',\n",
    "    setup='from __main__ import batched_dot_bmm',\n",
    "    globals={'x': x},\n",
    "    num_threads=num_threads,\n",
    "    label='Multithreaded batch dot',\n",
    "    sub_label='Implemented using bmm')\n",
    "\n",
    "print(t0.timeit(100))\n",
    "print(t1.timeit(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee1a07b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mul_sum(x, x):  1338.5 us\n",
      "mul_sum(x, x):  2128.9 us\n",
      "bmm(x, x):      881.5 us\n",
      "bmm(x, x):       61.7 us\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(10000, 1024, device='mps')\n",
    "\n",
    "t0 = timeit.Timer(\n",
    "    stmt='batched_dot_mul_sum(x, x)',\n",
    "    setup='from __main__ import batched_dot_mul_sum',\n",
    "    globals={'x': x})\n",
    "\n",
    "t1 = timeit.Timer(\n",
    "    stmt='batched_dot_bmm(x, x)',\n",
    "    setup='from __main__ import batched_dot_bmm',\n",
    "    globals={'x': x})\n",
    "\n",
    "# Ran each twice to show difference before/after warm-up\n",
    "print(f'mul_sum(x, x):  {t0.timeit(100) / 100 * 1e6:>5.1f} us')\n",
    "print(f'mul_sum(x, x):  {t0.timeit(100) / 100 * 1e6:>5.1f} us')\n",
    "print(f'bmm(x, x):      {t1.timeit(100) / 100 * 1e6:>5.1f} us')\n",
    "print(f'bmm(x, x):      {t1.timeit(100) / 100 * 1e6:>5.1f} us')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0bbdc91a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.benchmark.utils.common.Measurement object at 0x104f99580>\n",
      "batched_dot_mul_sum(x, x)\n",
      "setup: from __main__ import batched_dot_mul_sum\n",
      "  212.78 us\n",
      "  1 measurement, 100 runs , 1 thread\n",
      "<torch.utils.benchmark.utils.common.Measurement object at 0x103f726d0>\n",
      "batched_dot_bmm(x, x)\n",
      "setup: from __main__ import batched_dot_bmm\n",
      "  79.76 us\n",
      "  1 measurement, 100 runs , 1 thread\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W ParallelNative.cpp:230] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:230] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n"
     ]
    }
   ],
   "source": [
    "t0 = benchmark.Timer(\n",
    "    stmt='batched_dot_mul_sum(x, x)',\n",
    "    setup='from __main__ import batched_dot_mul_sum',\n",
    "    globals={'x': x})\n",
    "\n",
    "t1 = benchmark.Timer(\n",
    "    stmt='batched_dot_bmm(x, x)',\n",
    "    setup='from __main__ import batched_dot_bmm',\n",
    "    globals={'x': x})\n",
    "\n",
    "# Run only once since benchmark module does warm-up for us\n",
    "print(t0.timeit(100))\n",
    "print(t1.timeit(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f40a914",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
