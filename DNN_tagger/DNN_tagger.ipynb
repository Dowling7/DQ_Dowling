{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf0d6e61",
   "metadata": {},
   "source": [
    "# Particle tagger study at DarkQuest\n",
    "**Author:** Dowling Wong\n",
    "\n",
    "This is the demo on how to use the DNN based multi-class tagger for DarkQuest. In this demo, we are going to stick with dwong.py, the integrated python module for data process and tagging. Please refer to [dwong.py](dwong.py) for detailed implementation of code.\n",
    "\n",
    "## Clustering\n",
    "After reconstruct hits coordinates on EMCal, we have performed seed-searching algorithm and K-Means clustering. Since Kmeans clustering doesnot counted energy for each hits, centroid may change exceed tolerance during iterations. Return coords, labels, energy, seeds(centroids), in energy decrease order. Island clustering is in R&D stage due to computational complexity and inefficiency.\n",
    "\n",
    "## Link algorithm\n",
    "Using tracklet information of station2&3, we perform linear extrapolation to EMCal and station4 hodoscope. By tolerace distance 8cm(for most particles, this value should under 5cm), and assign closest unique track to every h4 hit. \n",
    "\n",
    "## Check point: CSV\n",
    "We use csv to save the processed data for each particle collected in each root file, following information will be saved as entries in csv, which also will be used as NN input/push back for ROOT: [\"evt_num\", \"gpz\", \"wid_x\", \"wid_y\", \"wew_x\", \"wew_y\", \"seed_x\", \"seed_y\",\n",
    "               \"trkl_x\", \"trkl_y\", \"trkl_z\", \"trkl_px\", \"trkl_py\", \"trkl_pz\", \"E/p\",\n",
    "               \"h4_41\", \"h4_42\", \"h4_43\", \"h4_44\", \"h4_45\", \"h4_46\"]  \n",
    "For sample code please see here: [sample code of csv](ref/gen_csv.ipynb)\n",
    "\n",
    "## DNN taggers\n",
    "Our DNN Multiclass tagger has 4 binary classifiers:  \n",
    "-[Electron/Positron](NNs/electronID_w_track_95), with AUC 0.95   \n",
    "-[Muon](NNs/muonID_w_track_99), with AUC 0.99  \n",
    "-[Photon](NNs/photonID_w_track_89), with AUC 0.89  \n",
    "-[Pi+/Pi-](NNs/pi+-_ID_w_track_86), with AUC 0.86  \n",
    "AUC meansured with background of equal weight mixture of electron, positron, photon/Pi0, Pi+, Pi-, Klong single particle guns. Assign particle tag by inspecting array of outputs by NNs.\n",
    "\n",
    "\n",
    "## Py-ROOT binding\n",
    "We have used pyroot and cppyy to implement the python-C++ binding. After data been processed by the tagger, we use pyroot to access the tree, create a buffer array of compatible data type by ROOT. Write our result into the buffer, create new branch in the tree, then push into it.  \n",
    "For reference, please see the sample code: [sample code of pyroot](ref/pyroot.ipynb), or [tutorial page](https://pep-root6.github.io/docs/analysis/python/pyroot.html)\n",
    "\n",
    "## TODOs\n",
    "-Some functionalities may need moderate adjustments due to the different purposes and structures of ROOT input. Please refer to [This repo](https://github.com/Dowling7/DQ_Dowling) for my full study on tagger. \n",
    "-R&D new features: ISland clustering, padded grid seed searching, and polygon-convex-hull linking algorithms.\n",
    "-Please contact me via slack or [email](dowlingwong@gmail.edu) for any question or request info. I will be happy to elaborate details for future member of DarkQuest who taking over this work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ea88bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dwong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66b5f62c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   wid_x  wid_y         wew_x         wew_y  seed_x  seed_y       trkl_x   \n",
      "0  2.765    0.0  7.598694e-01  2.520000e-09   -6.45   -0.46 -9999.000000  \\\n",
      "1  0.000    0.0  0.000000e+00  0.000000e+00    4.61    5.07     7.814219   \n",
      "2  0.000    0.0  8.880000e-16  0.000000e+00   -6.45   -0.46    -1.889574   \n",
      "3  0.000    0.0  0.000000e+00  0.000000e+00  -11.98   -0.46    -5.121831   \n",
      "4  2.765    0.0  6.611169e-01  1.020000e-07   -6.45   -5.99    -0.828422   \n",
      "\n",
      "        trkl_y     trkl_z      trkl_px      trkl_py      trkl_pz          E/p   \n",
      "0 -9999.000000 -9999.0000 -9999.000000 -9999.000000 -9999.000000 -9999.000000  \\\n",
      "1     7.352450  1896.8289    -0.458327     0.027412    49.525528     0.011990   \n",
      "2     3.099001  1896.8119    -0.432187    -0.041864    50.131190     0.008760   \n",
      "3     2.507322  1859.8807    -0.750870    -0.013618    49.482600     0.014594   \n",
      "4    -3.416130  1859.8684    -0.383605    -0.161098    41.867435     0.017327   \n",
      "\n",
      "         h4_41        h4_42        h4_43        h4_44        h4_45   \n",
      "0 -9999.000000 -9999.000000 -9999.000000 -9999.000000 -9999.000000  \\\n",
      "1     9.466787    11.228085    10.405888    10.171593 -9999.000000   \n",
      "2     9.466787    11.228085    10.405888    10.171593 -9999.000000   \n",
      "3     9.466787    11.228085 -9999.000000    10.171593 -9999.000000   \n",
      "4   -13.693213   -11.931915   -12.754112   -12.988407    -9.438768   \n",
      "\n",
      "         h4_46  \n",
      "0 -9999.000000  \n",
      "1     9.164667  \n",
      "2   -10.165333  \n",
      "3   -10.165333  \n",
      "4 -9999.000000  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the path to your CSV file\n",
    "file_path = 'NNs/sample_csv/p5_80_muon_1_10000.csv'\n",
    "\n",
    "# Specify the columns you want to import\n",
    "columns = [\n",
    "    \"wid_x\", \"wid_y\", \"wew_x\", \"wew_y\", \"seed_x\", \"seed_y\",\n",
    "    \"trkl_x\", \"trkl_y\", \"trkl_z\", \"trkl_px\", \"trkl_py\", \"trkl_pz\", \"E/p\",\n",
    "    \"h4_41\", \"h4_42\", \"h4_43\", \"h4_44\", \"h4_45\", \"h4_46\"\n",
    "]\n",
    "\n",
    "# Read the specified columns from the CSV\n",
    "data = pd.read_csv(file_path, usecols=columns)\n",
    "\n",
    "# Show the first few rows of the DataFrame\n",
    "print(data.head())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82888a3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 305us/step\n",
      "313/313 [==============================] - 0s 285us/step\n",
      "313/313 [==============================] - 0s 294us/step\n",
      "313/313 [==============================] - 0s 291us/step\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "class ParticleIdentifier:\n",
    "    def __init__(self, model_dir):\n",
    "        self.classes = ['electron', 'muon', 'pion', 'photon']\n",
    "        self.models = {\n",
    "            'electron': load_model(model_dir + \"electronID_w_track_95\"),\n",
    "            'muon': load_model(model_dir + \"muonID_w_track_99\"),\n",
    "            'pion': load_model(model_dir + \"pi+-_ID_w_track_86\"),\n",
    "            'photon': load_model(model_dir + \"photon_ID_w_track_89\")\n",
    "        }\n",
    "\n",
    "    def predict_classes(self, samples):\n",
    "        # Generate predictions for all models\n",
    "        predictions = [model.predict(samples) for model in self.models.values()]\n",
    "\n",
    "        # Stack predictions horizontally and find the index of the max probability\n",
    "        combined_probs = np.hstack(predictions)\n",
    "        class_indices = np.argmax(combined_probs, axis=1)\n",
    "\n",
    "        # Map indices to class names\n",
    "        predicted_classes = [self.classes[idx] for idx in class_indices]\n",
    "\n",
    "        return predicted_classes\n",
    "\n",
    "# Usage\n",
    "NN_dir = \"NNs/\"\n",
    "identifier = ParticleIdentifier(NN_dir)\n",
    "samples = data\n",
    "predicted_classes = identifier.predict_classes(samples)\n",
    "print(\"done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60295705",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['muon',\n",
       " 'muon',\n",
       " 'muon',\n",
       " 'muon',\n",
       " 'muon',\n",
       " 'muon',\n",
       " 'muon',\n",
       " 'muon',\n",
       " 'muon',\n",
       " 'muon',\n",
       " 'muon',\n",
       " 'muon',\n",
       " 'muon',\n",
       " 'muon',\n",
       " 'muon',\n",
       " 'muon',\n",
       " 'muon',\n",
       " 'muon',\n",
       " 'muon',\n",
       " 'muon']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_classes[10:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b88df515",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10004"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847ad7ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
