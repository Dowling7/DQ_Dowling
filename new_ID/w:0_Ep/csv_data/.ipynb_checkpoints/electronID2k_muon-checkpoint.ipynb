{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3zt5vYf8K1AF"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/jeffheaton/t81_558_deep_learning/blob/master/t81_558_class_04_2_multi_class.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "19pvQwY3K1AK",
    "outputId": "335d3fbc-71d4-425a-e168-4c2d1efb117f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: not using Google CoLab\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    %tensorflow_version 2.x\n",
    "    COLAB = True\n",
    "    print(\"Note: using Google CoLab\")\n",
    "except:\n",
    "    print(\"Note: not using Google CoLab\")\n",
    "    COLAB = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Your filenames and headers\n",
    "filenames = [\"p5_80_electron_0_10000.csv\", \"p5_80_muon_1_10000.csv\", \"p5_80_pi+_0_10000.csv\",\n",
    "\"p5_80_gamma_0_10000.csv\", \"p5_80_pi-_0_10000.csv\",\n",
    "\"p5_80_klong_0_10000.csv\", \"p5_80_pi0_0_10000.csv\",\"p5_80_positron_0_10000.csv\"]\n",
    "\n",
    "headers = [\"Label\", \"wid_x\", \"wid_y\", \"wew_x\", \"wew_y\", \"seed_x\", \"seed_y\",\n",
    "           \"trkl_x\", \"trkl_y\", \"trkl_z\", \"trkl_px\", \"trkl_py\", \"trkl_pz\",\n",
    "           \"h4_41\", \"h4_42\", \"h4_43\", \"h4_44\", \"h4_45\", \"h4_46\"]\n",
    "\n",
    "# Initialize an empty DataFrame to store concatenated data\n",
    "all_data = pd.DataFrame(columns=headers)\n",
    "\n",
    "# Loop through each filename\n",
    "for filename in filenames:\n",
    "    # Read the CSV file into a DataFrame\n",
    "    df = pd.read_csv(filename, names=headers) # if headers are not present in the file, otherwise remove names=...\n",
    "    # Concatenate vertically\n",
    "    all_data = pd.concat([all_data, df], axis=0, ignore_index=True)\n",
    "\n",
    "# Optionally: save the concatenated data to a new CSV file\n",
    "all_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "25ys9moDK1AP"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# Plot a confusion matrix.\n",
    "# cm is the confusion matrix, names are the names of the classes.\n",
    "def plot_confusion_matrix(cm, names, title='Confusion matrix', \n",
    "                            cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(names))\n",
    "    plt.xticks(tick_marks, names, rotation=45)\n",
    "    plt.yticks(tick_marks, names)\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    \n",
    "\n",
    "# Plot an ROC. pred - the predictions, y - the expected output.\n",
    "def plot_roc(pred,y):\n",
    "    fpr, tpr, _ = roc_curve(y, pred)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, label='ROC curve (area = %0.6f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC)')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=all_data[[\"wid_x\", \"wid_y\", \"wew_x\", \"wew_y\", \"seed_x\", \"seed_y\",\n",
    "           \"trkl_x\", \"trkl_y\", \"trkl_z\", \"trkl_px\", \"trkl_py\", \"trkl_pz\",\n",
    "           \"h4_41\", \"h4_42\", \"h4_43\", \"h4_44\", \"h4_45\", \"h4_46\"]].values\n",
    "y=all_data['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tchQMWrIK1AQ",
    "outputId": "e4be0d2b-d974-4917-bc0f-908917773c99"
   },
   "outputs": [],
   "source": [
    "# Classification neural network\n",
    "import numpy as np\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split into train/test\n",
    "x_train, x_test, y_train, y_test = train_test_split(    \n",
    "    x, y, test_size=0.25, random_state=42)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(18, input_dim=x.shape[1], activation='relu',\n",
    "                kernel_initializer='random_normal'))\n",
    "model.add(Dense(50,activation='relu',kernel_initializer='random_normal'))\n",
    "model.add(Dense(25,activation='relu',kernel_initializer='random_normal'))\n",
    "model.add(Dense(1,activation='sigmoid',kernel_initializer='random_normal'))\n",
    "model.compile(loss='binary_crossentropy', \n",
    "              optimizer=tensorflow.keras.optimizers.Adam(),\n",
    "              metrics =['accuracy'])\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, \n",
    "    patience=5, verbose=1, mode='auto', restore_best_weights=True)\n",
    "\n",
    "model.fit(x_train,y_train,validation_data=(x_test,y_test),\n",
    "          callbacks=[monitor],verbose=2,epochs=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "_95P1kTBK1AQ",
    "outputId": "35b353e5-0eaf-412f-83a3-1970e8e07bb1",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred = model(x_test)\n",
    "plot_roc(pred,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yElFCdNQK1AR"
   },
   "source": [
    "### Multiclass Classification Error Metrics\n",
    "\n",
    "If you want to predict more than one outcome, you will need more than one output neuron. Because a single neuron can predict two results, a neural network with two output neurons is somewhat rare. If there are three or more outcomes, there will be three or more output neurons. The following sections will examine several metrics for evaluating classification error. We will assess the following classification neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "wD57aaWKK1AR"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import zscore\n",
    "\n",
    "# Read the data set\n",
    "df = pd.read_csv(\n",
    "    \"https://data.heatonresearch.com/data/t81-558/jh-simple-dataset.csv\",\n",
    "    na_values=['NA','?'])\n",
    "\n",
    "# Generate dummies for job\n",
    "df = pd.concat([df,pd.get_dummies(df['job'],prefix=\"job\")],axis=1)\n",
    "df.drop('job', axis=1, inplace=True)\n",
    "\n",
    "# Generate dummies for area\n",
    "df = pd.concat([df,pd.get_dummies(df['area'],prefix=\"area\")],axis=1)\n",
    "df.drop('area', axis=1, inplace=True)\n",
    "\n",
    "# Missing values for income\n",
    "med = df['income'].median()\n",
    "df['income'] = df['income'].fillna(med)\n",
    "\n",
    "# Standardize ranges\n",
    "df['income'] = zscore(df['income'])\n",
    "df['aspect'] = zscore(df['aspect'])\n",
    "df['save_rate'] = zscore(df['save_rate'])\n",
    "df['age'] = zscore(df['age'])\n",
    "df['subscriptions'] = zscore(df['subscriptions'])\n",
    "\n",
    "# Convert to numpy - Classification\n",
    "x_columns = df.columns.drop('product').drop('id')\n",
    "x = df[x_columns].values\n",
    "dummies = pd.get_dummies(df['product']) # Classification\n",
    "products = dummies.columns\n",
    "y = dummies.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aggbZoEUK1AR",
    "outputId": "6893844e-1126-4e7d-b6cb-34b2ab04ab4f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "47/47 - 2s - loss: 1.4456 - accuracy: 0.4753 - val_loss: 1.1348 - val_accuracy: 0.4980 - 2s/epoch - 45ms/step\n",
      "Epoch 2/1000\n",
      "47/47 - 0s - loss: 1.1477 - accuracy: 0.4720 - val_loss: 1.0890 - val_accuracy: 0.4980 - 249ms/epoch - 5ms/step\n",
      "Epoch 3/1000\n",
      "47/47 - 0s - loss: 1.0847 - accuracy: 0.5040 - val_loss: 1.0205 - val_accuracy: 0.5380 - 482ms/epoch - 10ms/step\n",
      "Epoch 4/1000\n",
      "47/47 - 0s - loss: 0.9608 - accuracy: 0.5920 - val_loss: 0.9546 - val_accuracy: 0.5740 - 309ms/epoch - 7ms/step\n",
      "Epoch 5/1000\n",
      "47/47 - 0s - loss: 0.8508 - accuracy: 0.6480 - val_loss: 0.8616 - val_accuracy: 0.6600 - 290ms/epoch - 6ms/step\n",
      "Epoch 6/1000\n",
      "47/47 - 0s - loss: 0.7942 - accuracy: 0.6660 - val_loss: 0.8018 - val_accuracy: 0.6900 - 298ms/epoch - 6ms/step\n",
      "Epoch 7/1000\n",
      "47/47 - 0s - loss: 0.7581 - accuracy: 0.6927 - val_loss: 0.8044 - val_accuracy: 0.6740 - 271ms/epoch - 6ms/step\n",
      "Epoch 8/1000\n",
      "47/47 - 0s - loss: 0.7434 - accuracy: 0.6893 - val_loss: 0.7885 - val_accuracy: 0.6660 - 246ms/epoch - 5ms/step\n",
      "Epoch 9/1000\n",
      "47/47 - 0s - loss: 0.7522 - accuracy: 0.6867 - val_loss: 0.7835 - val_accuracy: 0.6720 - 281ms/epoch - 6ms/step\n",
      "Epoch 10/1000\n",
      "47/47 - 0s - loss: 0.7158 - accuracy: 0.6987 - val_loss: 0.7727 - val_accuracy: 0.6840 - 327ms/epoch - 7ms/step\n",
      "Epoch 11/1000\n",
      "47/47 - 0s - loss: 0.7129 - accuracy: 0.6887 - val_loss: 0.7966 - val_accuracy: 0.6820 - 231ms/epoch - 5ms/step\n",
      "Epoch 12/1000\n",
      "47/47 - 0s - loss: 0.7105 - accuracy: 0.6947 - val_loss: 0.7700 - val_accuracy: 0.6620 - 239ms/epoch - 5ms/step\n",
      "Epoch 13/1000\n",
      "47/47 - 0s - loss: 0.7119 - accuracy: 0.6940 - val_loss: 0.7680 - val_accuracy: 0.6700 - 254ms/epoch - 5ms/step\n",
      "Epoch 14/1000\n",
      "47/47 - 0s - loss: 0.6934 - accuracy: 0.7047 - val_loss: 0.7743 - val_accuracy: 0.6600 - 289ms/epoch - 6ms/step\n",
      "Epoch 15/1000\n",
      "47/47 - 0s - loss: 0.6904 - accuracy: 0.7093 - val_loss: 0.7564 - val_accuracy: 0.6860 - 266ms/epoch - 6ms/step\n",
      "Epoch 16/1000\n",
      "47/47 - 0s - loss: 0.6837 - accuracy: 0.7007 - val_loss: 0.7423 - val_accuracy: 0.7000 - 297ms/epoch - 6ms/step\n",
      "Epoch 17/1000\n",
      "47/47 - 0s - loss: 0.6783 - accuracy: 0.7120 - val_loss: 0.7519 - val_accuracy: 0.6840 - 258ms/epoch - 5ms/step\n",
      "Epoch 18/1000\n",
      "47/47 - 0s - loss: 0.6665 - accuracy: 0.7153 - val_loss: 0.7582 - val_accuracy: 0.6660 - 259ms/epoch - 6ms/step\n",
      "Epoch 19/1000\n",
      "47/47 - 0s - loss: 0.6702 - accuracy: 0.7000 - val_loss: 0.7504 - val_accuracy: 0.6880 - 271ms/epoch - 6ms/step\n",
      "Epoch 20/1000\n",
      "47/47 - 0s - loss: 0.6624 - accuracy: 0.7147 - val_loss: 0.7527 - val_accuracy: 0.6800 - 328ms/epoch - 7ms/step\n",
      "Epoch 21/1000\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "47/47 - 1s - loss: 0.6558 - accuracy: 0.7160 - val_loss: 0.7653 - val_accuracy: 0.6720 - 527ms/epoch - 11ms/step\n",
      "Epoch 21: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6a8ad5db50>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Classification neural network\n",
    "import numpy as np\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split into train/test\n",
    "x_train, x_test, y_train, y_test = train_test_split(    \n",
    "    x, y, test_size=0.25, random_state=42)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(100, input_dim=x.shape[1], activation='relu',\n",
    "                kernel_initializer='random_normal'))\n",
    "model.add(Dense(50,activation='relu',kernel_initializer='random_normal'))\n",
    "model.add(Dense(25,activation='relu',kernel_initializer='random_normal'))\n",
    "model.add(Dense(y.shape[1],activation='softmax',\n",
    "                kernel_initializer='random_normal'))\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer=tensorflow.keras.optimizers.Adam(),\n",
    "              metrics =['accuracy'])\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, \n",
    "                        verbose=1, mode='auto', restore_best_weights=True)\n",
    "model.fit(x_train,y_train,validation_data=(x_test,y_test),\n",
    "          callbacks=[monitor],verbose=2,epochs=1000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vr9U9rgvK1AR"
   },
   "source": [
    "### Calculate Classification Accuracy\n",
    " \n",
    "Accuracy is the number of rows where the neural network correctly predicted the target class.  Accuracy is only used for classification, not regression.\n",
    "\n",
    "$$ accuracy = \\frac{c}{N} $$\n",
    "\n",
    "Where $c$ is the number correct and $N$ is the size of the evaluated set (training or validation). Higher accuracy numbers are desired.\n",
    "\n",
    "As we just saw, by default, Keras will return the percent probability for each class. We can change these prediction probabilities into the actual iris predicted with **argmax**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "ldTptygpK1AR"
   },
   "outputs": [],
   "source": [
    "pred = model.predict(x_test)\n",
    "pred = np.argmax(pred,axis=1) \n",
    "# raw probabilities to chosen class (highest probability)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6_a5WcpJK1AS"
   },
   "source": [
    "Now that we have the actual iris flower predicted, we can calculate the percent accuracy (how many were correctly classified)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l7ZN4mO5K1AS",
    "outputId": "8a2bf888-d1e2-4317-bc55-855b78b5db99"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.7\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "y_compare = np.argmax(y_test,axis=1) \n",
    "score = metrics.accuracy_score(y_compare, pred)\n",
    "print(\"Accuracy score: {}\".format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1zlG17MKK1AS"
   },
   "source": [
    "### Calculate Classification Log Loss\n",
    "\n",
    "Accuracy is like a final exam with no partial credit.  However, neural networks can predict a probability of each of the target classes.  Neural networks will give high probabilities to predictions that are more likely.  Log loss is an error metric that penalizes confidence in wrong answers. Lower log loss values are desired.\n",
    "\n",
    "The following code shows the output of predict_proba:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "id": "ucCNS9XAK1AS",
    "outputId": "76375262-9554-4105-9d2c-3b088732e2df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy array of predictions\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.    , 0.1201, 0.7286, 0.1494, 0.0018, 0.    , 0.    ],\n",
       "       [0.    , 0.6962, 0.3016, 0.0001, 0.0022, 0.    , 0.    ],\n",
       "       [0.    , 0.7234, 0.2708, 0.0003, 0.0053, 0.0001, 0.    ],\n",
       "       [0.    , 0.3836, 0.6039, 0.0086, 0.0039, 0.    , 0.    ],\n",
       "       [0.    , 0.0609, 0.6303, 0.3079, 0.001 , 0.    , 0.    ]],\n",
       "      dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As percent probability\n",
      "[ 0.0001 12.0143 72.8578 14.9446  0.1823  0.0009  0.0001]\n",
      "Log loss score: 0.7423401429280638\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "# Don't display numpy in scientific notation\n",
    "np.set_printoptions(precision=4)\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "# Generate predictions\n",
    "pred = model.predict(x_test)\n",
    "\n",
    "print(\"Numpy array of predictions\")\n",
    "display(pred[0:5])\n",
    "\n",
    "print(\"As percent probability\")\n",
    "print(pred[0]*100)\n",
    "\n",
    "score = metrics.log_loss(y_test, pred)\n",
    "print(\"Log loss score: {}\".format(score))\n",
    "\n",
    "# raw probabilities to chosen class (highest probability)\n",
    "pred = np.argmax(pred,axis=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iU3NLdorK1AS"
   },
   "source": [
    "[Log loss](https://www.kaggle.com/wiki/LogarithmicLoss) is calculated as follows:\n",
    "\n",
    "$$ \\mbox{log loss} = -\\frac{1}{N}\\sum_{i=1}^N {( {y}_i\\log(\\hat{y}_i) + (1 - {y}_i)\\log(1 - \\hat{y}_i))} $$\n",
    "\n",
    "\n",
    "You should use this equation only as an objective function for classifications that have two outcomes. The variable y-hat is the neural networkâ€™s prediction, and the variable y is the known correct answer.  In this case, y will always be 0 or 1.  The training data have no probabilities. The neural network classifies it either into one class (1) or the other (0).  \n",
    "\n",
    "The variable N represents the number of elements in the training set the number of questions in the test.  We divide by N because this process is customary for an average.  We also begin the equation with a negative because the log function is always negative over the domain 0 to 1.  This negation allows a positive score for the training to minimize.\n",
    "\n",
    "You will notice two terms are separated by the addition (+).  Each contains a log function.  Because y will be either 0 or 1, then one of these two terms will cancel out to 0.  If y is 0, then the first term will reduce to 0.  If y is 1, then the second term will be 0.  \n",
    "\n",
    "If your prediction for the first class of a two-class prediction is y-hat, then your prediction for the second class is 1 minus y-hat.  Essentially, if your prediction for class A is 70% (0.7), then your prediction for class B is 30% (0.3).  Your score will increase by the log of your prediction for the correct class.  If the neural network had predicted 1.0 for class A, and the correct answer was A, your score would increase by log (1), which is 0. For log loss, we seek a low score, so a correct answer results in 0.  Some of these log values for a neural network's probability estimate for the correct class:\n",
    "\n",
    "* -log(1.0) = 0\n",
    "* -log(0.95) = 0.02\n",
    "* -log(0.9) = 0.05\n",
    "* -log(0.8) = 0.1\n",
    "* -log(0.5) = 0.3\n",
    "* -log(0.1) = 1\n",
    "* -log(0.01) = 2\n",
    "* -log(1.0e-12) = 12\n",
    "* -log(0.0) = negative infinity\n",
    "\n",
    "As you can see, giving a low confidence to the correct answer affects the score the most.  Because log (0) is negative infinity, we typically impose a minimum value.  Of course, the above log values are for a single training set element.  We will average the log values for the entire training set.\n",
    "\n",
    "The log function is useful to penalizing wrong answers.  The following code demonstrates the utility of the log function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 360
    },
    "id": "g5Zv2tgNK1AT",
    "outputId": "f0861083-7809-406f-9970-4c83505ca14a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: RuntimeWarning: divide by zero encountered in log\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib.pyplot import figure, show\n",
    "from numpy import arange, sin, pi\n",
    "\n",
    "#t = arange(1e-5, 5.0, 0.00001)\n",
    "#t = arange(1.0, 5.0, 0.00001) # computer scientists\n",
    "t = arange(0.0, 1.0, 0.00001)  # data     scientists\n",
    "\n",
    "fig = figure(1,figsize=(12, 10))\n",
    "\n",
    "ax1 = fig.add_subplot(211)\n",
    "ax1.plot(t, np.log(t))\n",
    "ax1.grid(True)\n",
    "ax1.set_ylim((-8, 1.5))\n",
    "ax1.set_xlim((-0.1, 2))\n",
    "ax1.set_xlabel('x')\n",
    "ax1.set_ylabel('y')\n",
    "ax1.set_title('log(x)')\n",
    "\n",
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZaRtddpcK1AT"
   },
   "source": [
    "### Confusion Matrix\n",
    "\n",
    "A confusion matrix shows which predicted classes are often confused for the other classes. The vertical axis (y) represents the true labels and the horizontal axis (x) represents the predicted labels. When the true label and predicted label are the same, the highest values occur down the diagonal extending from the upper left to the lower right. The other values, outside the diagonal, represent incorrect predictions. For example, in the confusion matrix below, the value in row 2, column 1 shows how often the predicted value A occurred when it should have been B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 454
    },
    "id": "1pvqhwRcK1AT",
    "outputId": "89d39b8b-af2d-4861-81da-905acb8c5528"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized confusion matrix\n",
      "[[0.95 0.05 0.   0.   0.   0.   0.  ]\n",
      " [0.02 0.78 0.2  0.   0.   0.   0.  ]\n",
      " [0.   0.29 0.7  0.01 0.   0.   0.  ]\n",
      " [0.   0.   0.71 0.29 0.   0.   0.  ]\n",
      " [0.   1.   0.   0.   0.   0.   0.  ]\n",
      " [0.59 0.41 0.   0.   0.   0.   0.  ]\n",
      " [1.   0.   0.   0.   0.   0.   0.  ]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y_compare, pred)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Normalize the confusion matrix by row (i.e by the number of samples\n",
    "# in each class)\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "print('Normalized confusion matrix')\n",
    "print(cm_normalized)\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cm_normalized, products, \n",
    "        title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "G0KvHKadK1AT"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "name": "t81_558_class_04_2_multi_class.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
