{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f4cfc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "X, Y = make_classification(\n",
    "  n_samples=100, n_features=4, n_redundant=0,\n",
    "  n_informative=3,  n_clusters_per_class=2, n_classes=3\n",
    ")#This is to generate the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "840293e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100\n"
     ]
    }
   ],
   "source": [
    "#print(X,Y)#so X is the data and Y is the label.\n",
    "print(len(X),len(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b391af82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "  X, Y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "68b40cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "class Data(Dataset):\n",
    "    def __init__(self, X_train, y_train):\n",
    "    # need to convert float64 to float32 else \n",
    "    # will get the following error\n",
    "    # RuntimeError: expected scalar type Double but found Float\n",
    "        self.X = torch.from_numpy(X_train.astype(np.float32))\n",
    "    # need to convert float64 to Long else \n",
    "    # will get the following error\n",
    "    # RuntimeError: expected scalar type Long but found Float\n",
    "        self.y = torch.from_numpy(y_train).type(torch.LongTensor)\n",
    "        self.len = self.X.shape[0]\n",
    "  \n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.y[index]\n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c5bd77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata = Data(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d170202d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[-0.0611, -4.4074,  1.7794,  2.7314],\n",
      "        [-1.2831,  1.0859, -1.3995, -1.0374],\n",
      "        [-0.6698,  1.6577,  1.1312,  1.1259],\n",
      "        [ 0.9646,  1.1478, -0.1131,  1.5549],\n",
      "        [-0.6522,  0.4783,  1.3912,  0.8054],\n",
      "        [ 0.1309, -2.5601,  1.1008, -1.4090],\n",
      "        [-0.7431, -0.1255,  3.3924, -0.9593],\n",
      "        [ 0.3508, -0.9283,  0.5000,  1.8632],\n",
      "        [ 0.3931,  2.0356,  2.3663, -0.8296],\n",
      "        [ 0.7373,  0.2356,  1.2257,  0.0806],\n",
      "        [-1.7103, -1.3369, -1.0340, -2.2846]]), tensor([0, 2, 0, 0, 0, 1, 1, 0, 1, 0, 1]))\n"
     ]
    }
   ],
   "source": [
    "print(traindata[6:17])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c4b49921",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "trainloader = DataLoader(traindata, batch_size=batch_size, \n",
    "                         shuffle=True)#num_workers is for parallel loading, caused problem\n",
    "#RuntimeError: DataLoader worker (pid(s) 45243, 45244) exited unexpectedly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cf83d8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "# number of features (len of X cols)\n",
    "input_dim = 4\n",
    "# number of hidden layers\n",
    "hidden_layers = 25\n",
    "# number of classes (unique of y)\n",
    "output_dim = 3\n",
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_dim, hidden_layers)\n",
    "        self.linear2 = nn.Linear(hidden_layers, output_dim)\n",
    "    def forward(self, x):\n",
    "        x = torch.sigmoid(self.linear1(x))\n",
    "        x = self.linear2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c00930f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = Network()\n",
    "#print(clf.parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bee5ce28",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(clf.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3b18fee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2,     1] loss: 0.00045\n",
      "[2,     2] loss: 0.00107\n",
      "[2,     3] loss: 0.00156\n",
      "[2,     4] loss: 0.00211\n",
      "[2,     5] loss: 0.00265\n",
      "[2,     6] loss: 0.00315\n",
      "[2,     7] loss: 0.00368\n",
      "[2,     8] loss: 0.00416\n",
      "[2,     9] loss: 0.00469\n",
      "[2,    10] loss: 0.00517\n",
      "[2,    11] loss: 0.00564\n",
      "[2,    12] loss: 0.00624\n",
      "[2,    13] loss: 0.00678\n",
      "[2,    14] loss: 0.00727\n",
      "[2,    15] loss: 0.00770\n",
      "[2,    16] loss: 0.00827\n",
      "[2,    17] loss: 0.00884\n"
     ]
    }
   ],
   "source": [
    "epochs = 2\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "for i, data in enumerate(trainloader, 0):\n",
    "    inputs, labels = data\n",
    "    # set optimizer to zero grad to remove previous epoch gradients\n",
    "    optimizer.zero_grad()\n",
    "    # forward propagation\n",
    "    outputs = clf(inputs)\n",
    "    loss = criterion(outputs, labels)\n",
    "    # backward propagation\n",
    "    loss.backward()\n",
    "    # optimize\n",
    "    optimizer.step()\n",
    "    running_loss += loss.item()\n",
    "  # display statistics\n",
    "    print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7140da4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the trained model\n",
    "PATH = './mymodel.pth'\n",
    "torch.save(clf.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7db73005",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = Network()\n",
    "clf.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9478169f",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'_MultiProcessingDataLoaderIter' object has no attribute 'next'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m testloader \u001b[38;5;241m=\u001b[39m DataLoader(testdata, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, \n\u001b[1;32m      3\u001b[0m                         shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m      4\u001b[0m dataiter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m(testloader)\n\u001b[0;32m----> 5\u001b[0m inputs, labels \u001b[38;5;241m=\u001b[39m \u001b[43mdataiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext\u001b[49m()\n",
      "\u001b[0;31mAttributeError\u001b[0m: '_MultiProcessingDataLoaderIter' object has no attribute 'next'"
     ]
    }
   ],
   "source": [
    "testdata = Data(X_test, Y_test)\n",
    "testloader = DataLoader(testdata, batch_size=batch_size, \n",
    "                        shuffle=True, num_workers=2)\n",
    "dataiter = iter(testloader)\n",
    "inputs, labels = dataiter.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6c9d20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
